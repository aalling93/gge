{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "land = Landsat()\n",
    "land.load_data(\"/Users/kaaso/Documents/phd/coding/gge/data/location/eigil/img/satelliteSensors.landsat_ID20240703T2115-0000000000-0000000000.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = land.dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 3695, 7680)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import gc\n",
    "import sys\n",
    "from typing import Tuple, List, Union, Optional\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "from gge.raster.utils import init_transformer\n",
    "from gge.raster.geometry import transform_to_lonlat, transform_to_indices\n",
    "from gge.raster.geometry import GeoCoordinate, Coordinate\n",
    "from shapely.geometry import Polygon\n",
    "from gge.algorithms.band_math.indices import compute_NDVI, compute_EVI, compute_NDWI\n",
    "\n",
    "class Landsat:\n",
    "    def __init__(\n",
    "        self,\n",
    "        validate: bool = False,\n",
    "        verbose: int = 0,\n",
    "    ):\n",
    "        \"\"\" \"\"\"\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.dataset = None\n",
    "        self._is_valid = False\n",
    "\n",
    "    def load_data(self, data_path: Optional[str] = None):\n",
    "\n",
    "        self.dataset = rioxarray.open_rasterio(data_path)\n",
    "        self.transformer, self.crs = init_transformer(data_path)\n",
    "\n",
    "        self.band_names = {\"band_name\":self.dataset.long_name, \"band_index\": land.dataset.band.data.tolist()}\n",
    "        \n",
    "\n",
    "        return None\n",
    "\n",
    "    def yx(self, rows: Union[int, List[int]], cols: Union[int, List[int]]) -> Union[GeoCoordinate, List[GeoCoordinate]]:\n",
    "        \"\"\"Get geographic coordinates (lon, lat) from pixel indices.\n",
    "        Args:\n",
    "            row (int): Pixel row index. (y)\n",
    "            col (int): Pixel column index. (x)\n",
    "        Returns:\n",
    "            GeoCoordinate: Latitude and longitude.\n",
    "        \"\"\"\n",
    "        if isinstance(rows, list) and isinstance(cols, list):\n",
    "            if len(rows) != len(cols):\n",
    "                raise ValueError(\"Lists of rows and cols must be of equal length.\")\n",
    "            return [transform_to_lonlat(self.transformer, self.crs, row, col) for row, col in zip(rows, cols)]\n",
    "        elif isinstance(rows, int) and isinstance(cols, int):\n",
    "            return transform_to_lonlat(self.transformer, self.crs, rows, cols)\n",
    "        else:\n",
    "            raise ValueError(\"Rows and cols must be both single values or lists of equal length.\")\n",
    "\n",
    "    def lonlat(self, lons: Union[float, List[float]], lats: Union[float, List[float]]) -> Union[Coordinate, List[Coordinate]]:\n",
    "        \"\"\"Get pixel indices from geographic coordinates ( lon, lat).\n",
    "\n",
    "        Args:\n",
    "            lon (float): Longitude.\n",
    "            lat (float): Latitude.\n",
    "\n",
    "        Returns:\n",
    "            Coordinate: Pixel row and column indices.\n",
    "        \"\"\"\n",
    "        if isinstance(lats, list) and isinstance(lons, list):\n",
    "            if len(lats) != len(lons):\n",
    "                raise ValueError(\"Lists of latitudes and longitudes must be of equal length.\")\n",
    "            return [transform_to_indices(self.transformer, self.crs, lat, lon) for lat, lon in zip(lats, lons)]\n",
    "        elif isinstance(lats, float) and isinstance(lons, float):\n",
    "            return transform_to_indices(self.transformer, self.crs, lats, lons)\n",
    "        else:\n",
    "            raise ValueError(\"Latitudes and longitudes must be both single values or lists of equal length.\")\n",
    "\n",
    "    def _raster_extent_to_polygon(self) -> Polygon:\n",
    "        \"\"\"\n",
    "        Converts the extent of a rasterio dataset with GCPs to a geographic polygon.\n",
    "\n",
    "        Parameters:\n",
    "        - src: rasterio dataset\n",
    "\n",
    "        Returns:\n",
    "        - A shapely Polygon object representing the geographic extent of the raster.\n",
    "        \"\"\"\n",
    "        c, rows, cols = self.shape()\n",
    "        top_left = self.yx(0, 0)\n",
    "        top_right = self.yx(0, cols)\n",
    "        bottom_right = self.yx(rows, cols)\n",
    "        bottom_left = self.yx(rows, 0)\n",
    "        geo_coords = [top_left, top_right, bottom_right, bottom_left, top_left]\n",
    "        polygon = Polygon(geo_coords)\n",
    "        return polygon\n",
    "\n",
    "    def _validate(self) -> bool:\n",
    "        if self.data_path is None:\n",
    "            logging.error(\"No data path provided.\")\n",
    "            return False\n",
    "\n",
    "    @property\n",
    "    def data_paths(self):\n",
    "        return self.data_paths\n",
    "\n",
    "    @data_paths.setter\n",
    "    def data_paths(self, value: Union[str, list, List] = None) -> None:\n",
    "        \"\"\" \"\"\"\n",
    "        self._data_paths = value\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> Union[tuple, Tuple[int, int, int]]:\n",
    "        return (\n",
    "            self.dataset.sizes[\"band\"],\n",
    "            self.dataset.sizes[\"y\"],\n",
    "            self.dataset.sizes[\"x\"],\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def size(self) -> Union[tuple, Tuple[int, int, int]]:\n",
    "        return (\n",
    "            self.dataset.sizes[\"band\"],\n",
    "            self.dataset.sizes[\"y\"],\n",
    "            self.dataset.sizes[\"x\"],\n",
    "        )\n",
    "    \n",
    "    def data(\n",
    "        self,\n",
    "        band: Union[int, None] = None,\n",
    "        y: Union[tuple, Tuple[int, int], None] = None,\n",
    "        x: Union[tuple, Tuple[int, int], None] = None,\n",
    "    ) -> Union[None, np.ndarray]:\n",
    "\n",
    "        # we want to slice like this self.dataset.sel(band = 1, y = slice(0,100), x=slice(0, 100))\n",
    "        # depending on the intiuts.. However, it is okay to only slice on the band, or x,..\n",
    "\n",
    "        # band\n",
    "        if band is not None and y is None and x is None:\n",
    "            return self.dataset.sel(band=band).to_array()[0]\n",
    "        # band and y\n",
    "        elif band is not None and y is not None and x is not None:\n",
    "            return self.dataset.sel(band=band, y=slice(y[0], y[1]), x=slice(x[0], x[1])).to_array()[0]\n",
    "        # band and x and y\n",
    "        elif band is not None and y is not None and x is None:\n",
    "            return self.dataset.sel(band=band, y=slice(y[0], y[1])).to_array()[0]\n",
    "        # band and x\n",
    "        elif band is not None and y is None and x is not None:\n",
    "            return self.dataset.sel(band=band, x=slice(x[0], x[1])).to_array()[0]\n",
    "        # y and x\n",
    "        elif band is None and y is not None and x is not None:\n",
    "            return self.dataset.sel(y=slice(y[0], y[1]), x=slice(x[0], x[1])).to_array()[0]\n",
    "        # y\n",
    "        elif band is None and y is not None and x is None:\n",
    "            return self.dataset.sel(y=slice(y[0], y[1])).to_array()[0]\n",
    "        # x\n",
    "        elif band is None and y is None and x is not None:\n",
    "            return self.dataset.sel(x=slice(x[0], x[1])).to_array()[0]\n",
    "        else:\n",
    "            return self.dataset.to_array()[0]\n",
    "\n",
    "    def close_dataset(self) -> None:\n",
    "        \"\"\"\n",
    "        Closes the dataset to free resources.\n",
    "        \"\"\"\n",
    "        if self.dataset:\n",
    "            self.dataset.close()\n",
    "\n",
    "    @property\n",
    "    def item_type(self):\n",
    "        return self._item_type\n",
    "\n",
    "    @item_type.setter\n",
    "    def item_type(self, value):\n",
    "        valid_bands = [\n",
    "            \"SR_B1\",\n",
    "            \"SR_B2\",\n",
    "            \"SR_B3\",\n",
    "            \"SR_B4\",\n",
    "            \"SR_B5\",\n",
    "            \"SR_B6\",\n",
    "            \"SR_B7\",\n",
    "            \"SR_QA_AEROSOL\"\n",
    "            \"ST_B10\",\n",
    "            \"ST_ATRAN\",\n",
    "            \"NDVI\",\n",
    "            \"EVI\",\n",
    "            \"NDWI\",\n",
    "            \"RGB\",\n",
    "        ]\n",
    "        if value.upper() in valid_bands:\n",
    "            self._item_type = value\n",
    "        else:\n",
    "            raise ValueError(\"Invalid item type.\")\n",
    "        \n",
    "\n",
    "        def __getitem__(self, item):\n",
    "            img = self.images_data[item]\n",
    "            metadata = img.get(\"metadata\")\n",
    "            bands = img.get(\"image_bands\")\n",
    "\n",
    "            landsat_number = int(metadata[\"LANDSAT_PRODUCT_ID\"][3])\n",
    "\n",
    "            if self._item_type in [\"SR_B1\", \"SR_B2\", \"SR_B3\", \"SR_B4\", \"SR_B5\", \"SR_B6\", \"SR_B7\", \"SR_B8\"]:\n",
    "                array = bands[self._item_type]\n",
    "            elif self._item_type.upper() == \"NDVI\":\n",
    "                array = compute_NDVI(bands[\"SR_B4\"], bands[\"SR_B5\"])\n",
    "            elif self._item_type.upper() == \"EVI\":\n",
    "                array = compute_EVI(bands[\"SR_B4\"], bands[\"SR_B5\"], bands[\"SR_B2\"])\n",
    "            elif self._item_type.upper() == \"NDWI\":\n",
    "                if landsat_number == 4 or landsat_number == 5:\n",
    "                    array = compute_NDWI(bands[\"SR_B3\"], bands[\"SR_B5\"])\n",
    "                elif landsat_number == 7:\n",
    "                    array = compute_NDWI(bands[\"SR_B3\"], bands[\"SR_B5\"])\n",
    "                elif landsat_number == 8:\n",
    "                    array = compute_NDWI(bands[\"SR_B3\"], bands[\"SR_B5\"])\n",
    "                else:\n",
    "                    try:\n",
    "                        array = compute_NDWI(bands[\"SR_B3\"], bands[\"SR_B4\"])\n",
    "                    except KeyError:\n",
    "                        self.logger.error(f\"Band {self._item_type} not found in the image.\")\n",
    "                        array = None\n",
    "            elif self._item_type.upper() == \"RGB\":\n",
    "                array = self.convert_to_plotable_rgb(\n",
    "                    {\n",
    "                        \"SR_B4\": bands[\"SR_B4\"],\n",
    "                        \"SR_B3\": bands[\"SR_B3\"],\n",
    "                        \"SR_B2\": bands[\"SR_B2\"],\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Band {self._item_type} not found in the image.\")\n",
    "\n",
    "            return array, metadata\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"\"\"S1(data_path=\"{self.data_path}\", validate= {self.validate}, verbose=0, save_path=\"{self.save_path}\")\"\"\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"Sentinel-1 Data Handler for {self.data_path}\"\n",
    "\n",
    "    def __sizeof__(self) -> tuple:\n",
    "        \"\"\"\n",
    "        Estimates the size of the S1 instance in bytes, distinguishing between NumPy arrays and other attributes.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple where the first element is the total size excluding NumPy arrays, and the second element\n",
    "                   is the total size of all NumPy arrays.\n",
    "        \"\"\"\n",
    "        base_size = super().__sizeof__()\n",
    "        non_numpy_size = base_size  # Start with the base object size\n",
    "        numpy_size = 0  # Initialize numpy arrays size\n",
    "\n",
    "        attributes = [\n",
    "            self.verbose,\n",
    "            self.dataset,\n",
    "        ]\n",
    "\n",
    "        for attr in attributes:\n",
    "            if isinstance(attr, np.ndarray):\n",
    "                numpy_size += attr.nbytes\n",
    "            elif hasattr(attr, \"__sizeof__\"):\n",
    "                non_numpy_size += attr.__sizeof__()\n",
    "            else:\n",
    "                non_numpy_size += sys.getsizeof(attr)\n",
    "\n",
    "        if self.dataset and not isinstance(self.dataset, np.ndarray):\n",
    "            non_numpy_size += sys.getsizeof(self.dataset)\n",
    "\n",
    "        return (non_numpy_size, numpy_size)\n",
    "\n",
    "    def __bool__(self) -> bool:\n",
    "        return self._is_valid\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.rio.count if self.dataset else 0\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb) -> None:\n",
    "        self.dataset.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.long_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat.satelliteSensors.landsat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gge_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
